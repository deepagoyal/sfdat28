{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy       # python wrapper for twitter api\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "# step 0, get your own twitter credentials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is my own personal twitter api information\n",
    "# if you could be so kind as to sign up yourself on both twitter and mashape that'd be great :)\n",
    "# It's FREEEEEEE\n",
    "api_key = 'g5uPIpw80nULQI1gfklv2zrh4'\n",
    "api_secret = 'cOWvNWxYvPmEZ0ArZVeeVVvJu41QYHdUS2GpqIKtSQ1isd5PJy'\n",
    "access_token = '49722956-TWl8J0aAS6KTdcbz3ppZ7NfqZEmrwmbsb9cYPNELG'\n",
    "access_secret = '3eqrVssF3ppv23qyflyAto8wLEiYRA8sXEPSghuOJWTub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Documentation is your friend! http://docs.tweepy.org/en/v3.1.0/\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth) # returns a tweepy authorization handler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Use Twitter API to stream and store tweets (300 per candidate)\n",
    "# 37.781157,-122.39872 is the lat,lng for SF\n",
    "music_tweets = api.search(q='#music', count=100, geocode=\"37.781157,-122.398720,10mi\")+\\\n",
    "api.search(q='#concert', count=100, geocode=\"37.781157,-122.398720,10mi\")+\\\n",
    "api.search(q='#band', count=100, geocode=\"37.781157,-122.398720,10mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(music_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'#Nashville Council Agrees to Give #WarnerMusic $500 Per New Job Created #music #musicindustry #musicnews\\u2026 https://t.co/4wvMfjX7LA'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_tweets[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__eq__', '__format__', '__getattribute__', '__getstate__', '__hash__', '__init__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_json', 'author', 'contributors', 'coordinates', 'created_at', 'destroy', 'entities', 'favorite', 'favorite_count', 'favorited', 'geo', 'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'metadata', 'parse', 'parse_list', 'place', 'possibly_sensitive', 'retweet', 'retweet_count', 'retweeted', 'retweets', 'source', 'source_url', 'text', 'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "# wrappers come with built in python attributes and methods!\n",
    "print dir(music_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-11-17 15:16:34\n",
      "#Nashville Council Agrees to Give #WarnerMusic $500 Per New Job Created #music #musicindustry #musicnewsâ€¦ https://t.co/4wvMfjX7LA\n",
      "0\n",
      "False\n",
      "en\n",
      "None\n",
      "0\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print music_tweets[0].created_at\n",
    "print music_tweets[0].text\n",
    "print music_tweets[0].favorite_count\n",
    "print music_tweets[0].favorited\n",
    "print music_tweets[0].lang\n",
    "print music_tweets[0].geo\n",
    "print music_tweets[0].retweet_count\n",
    "print music_tweets[0].retweeted\n",
    "print music_tweets[0].coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify the tweets to make a nice dictionary\n",
    "def parse_status_objects(tweet_list):\n",
    "    modified_tweets = list()\n",
    "    for x in tweet_list:\n",
    "        modified_tweets.append( [\n",
    "                    x.created_at,\n",
    "                    x.text,\n",
    "                    x.favorite_count,\n",
    "                    x.favorited,\n",
    "                    x.lang,\n",
    "                    x.geo,\n",
    "                    x.retweet_count,\n",
    "                    x.retweeted,\n",
    "                    x.coordinates\n",
    "                ])\n",
    "    return modified_tweets\n",
    "        \n",
    "music_tweets = parse_status_objects(music_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2016, 11, 17, 15, 16, 34), u'#Nashville Council Agrees to Give #WarnerMusic $500 Per New Job Created #music #musicindustry #musicnews\\u2026 https://t.co/4wvMfjX7LA', 0, False, u'en', None, 0, False, None]\n"
     ]
    }
   ],
   "source": [
    "print music_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 Create a dataframe that combines all of the tweets from each candidate\n",
    "# To do so, you will need to concat the data frames\n",
    "# so each row is a tweet and your columns should be \n",
    "# date, text, favorite_count,favorited, language, geocode, retweet count, retweeted, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 Create a function to take in a string and output the textblob sentiment of that string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 Add a column to your data frame called 'sentiment'\n",
    "# which holds the sentiment of that tweet (hint: use the function from #3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5 create a word count column, which holds the number of words in the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use countvectorizer to create a document-term matrix and concatinate it to your main dataframe\n",
    "#(hint you should now have thousands of columns)\n",
    "# Don't add count vectorizer result to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6 Use kmean to create clusters for the dataframe of words only (choose an optimal k)\n",
    "# Don't add clusters to the original dataframe yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7 Explore the clusters\n",
    "# What is interesting? Surprising? Can you draw any inferences about each cluster?\n",
    "# Was this enough to find any relevant topics about music tweets?\n",
    "# Can you give any of the clusters name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8. use LSA to obtain better topic clusters. Can you give any of the clusters name?\n",
    "# Make a boxplot of sentiment for each candidate by the \"democrat\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9. Think of 3 more hashtags you wish to explore (all of them should be about the same thing)\n",
    "# and make a dataframe the same way we did in the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10. Use whatever clustering method (DBSCAN, LSA, KMEANS) you deem best (silhouette coeff?) and make a supervised model out of it\n",
    "# IE try to predict the clusters you obtained by using the features\n",
    "# Note clustering does not HAVE to include text if you do not want it to in that case LSA won't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11. cross validate and create the best possible supervised model for your new clusters on your new daa\n",
    "# You may use the music data if you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [alphavuenv]",
   "language": "python",
   "name": "Python [alphavuenv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
